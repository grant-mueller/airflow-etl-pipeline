{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d63af6a",
   "metadata": {},
   "source": [
    "# ETL Pipeline Development Notebook\n",
    "\n",
    "This notebook demonstrates how to run and develop the ETL pipeline interactively using Jupyter within Docker containers. We'll walk through setting up the environment and running each pipeline component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "import sys\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1991b2c6",
   "metadata": {},
   "source": [
    "## Check Project Dependencies\n",
    "\n",
    "Let's verify the current project dependencies and ensure we have Jupyter support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../requirements.txt', 'r') as f:\n",
    "    requirements = f.read()\n",
    "print(\"Current requirements.txt contents:\")\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca8034",
   "metadata": {},
   "source": [
    "## Pipeline Components\n",
    "\n",
    "Let's import and test each component of our ETL pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline components\n",
    "from etl_scripts.extract import extract_data\n",
    "from etl_scripts.transform import clean_data\n",
    "from etl_scripts.load import load_to_db\n",
    "from etl_scripts.analytics import run_analytics\n",
    "\n",
    "print(\"Pipeline components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250d7d5",
   "metadata": {},
   "source": [
    "## Run Pipeline Components\n",
    "\n",
    "Now let's execute each component of the pipeline sequentially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract data\n",
    "print(\"Starting extraction...\")\n",
    "extract_data()\n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transform data\n",
    "print(\"Starting transformation...\")\n",
    "clean_data()\n",
    "print(\"Transformation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0baa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load data\n",
    "print(\"Starting load...\")\n",
    "load_to_db()\n",
    "print(\"Load complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb766a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run analytics\n",
    "print(\"Starting analytics...\")\n",
    "run_analytics()\n",
    "print(\"Analytics complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
